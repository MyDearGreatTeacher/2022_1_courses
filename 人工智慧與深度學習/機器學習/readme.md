
#
```
ChapterQ1 機器學習介紹
1.1 什麼是機器學習

1959 年Arthur Samuel 給機器學習的定義是：
Field of study that gives computers the ability to learn without being explicitly
programmed

Tom M. Mitchell 在操作層面列出了更直觀的定義：
A computer program is said to learn from experience E with respect to some
class of tasks T and performance measure P, if its performance at tasks in T,
as measured by P, improves with experience E.

1.2 機器學習有什麼用

1.3 機器學習的分類
1.4 機器學習應用程式開發的典型步驟
1.4.1 資料獲取和標記
1.4.2 資料清洗
1.4.3 特徵選擇
1.4.4 模型選擇
1.4.5 模型訓練和測試
1.4.6 模型效能評估和最佳化
1.4.7 模型使用
```
```

與人類的差距大幾個數量級。這是個讓人「腦洞」大開的想像。網上有一篇
很火的翻譯過來的文章「為什麼最近有很多名人，例如比爾蓋茲，馬斯克、
霍金等，讓人們警惕人工智慧？」，推薦讀者閲讀一下，其比普通的科幻小
説要好看得多。喜歡閲讀英文原文的讀者，可以在waitbutwhy.com 上搜索
"The Al Revolution" 。
機器學習的分類
機器學習可以分成以下兩種。
監督式學習(Supervised learning) 透過大量已知的輸入和輸出相配對的
資料，讓電腦從中學習出規律，進—步能針對—個新的輸入做出合理的
輸出預測。舉例來説，我們有大量不同特徵（面積、地理位置、朝向丶
開發廠商等）的房子的價格資料，透過學習這些資料，預測—亻目已知特
徵的房子價格，這種稱為回歸學習(Regression learning) ，即輸出結果是
—個實際的數值，它的預測模型是—個連續的函數。再例如我們有大量
的郵件，每個郵件都已經標記是否是垃圾郵件。透過學習這些已標記的
郵件資料，最後得出一個模型，這個模型對新的郵件，能準確地判斷出
該郵件是否是垃圾郵件，這種稱為分類學習(Classfication learning) ，即
輸出結果是離散的，即不是輸出1 表示是垃圾郵件，就是輸出0 表示不
是垃圾郵件。
無監督學習(Unsupervised learning) 透過學習大量的無標記的資料，
去分析出資料本身的內在特點和結構。舉例來説，我們有大量的使用者
購物的歷史記錄資訊，從資料中去分析使用者的不和類別。針對這個問
題，我們最後能劃分幾個類別？每個類別有哪些特點？我們事先是不知
道的。途個稱為分群(Clustering) 。這裡需要特別注意和監督式學習裡的
分類的差別，分類問題是我們已經知道了有哪幾種類別；而分群問題，
是我們在分析資料之前其實是不知道有哪些類別的。即分類問題是在已
知答案裡選擇一個，而分群問題的答案是未知的，需要利用演算法從資
料裡採擷出資料的特點和結構。

網路上流傳—個陰謀論：如果你是—個很好説話的人，網購時收到有瑕
疵的商品的機率會比較高。為什麼呢？理由是電子商務庫存裡會有—部
分有小瑕疵但不影響使用的商品，為了確保這些商品順利地賣出去並且
不影響使用者體驗，不被使用者客訴，他們會把有瑕疵的商品賣給那些
很好説話的人。可問題是，哪些人是好説話的人呢？—個最簡單的方法
是直接把有小瑕疵的商品寄給＿個使用者，如果這個使用者沒有客訴或
退貨，並且還列出了好評，就説明他是個好説話的人。還可以透過機器
學習來最佳化這一過程。電子商務網站有你的大量交易記錄和行為記
錄，如果你從來沒有客訴過，買之前也不會和賣家溝通太久，買之後也
沒有上網評價，或全部給好評，那麼機器學習演算法從你的行為特徵中
會判斷你為「好對付」的人。這樣你就成了電子商務們的瑕疵商品的傾
銷物件了。在這個案例中，電子商務透過使用者的行為和交易資料，分
析出不同的使用者特點，如哪些人是「老實」人丶哪些人是有車—族、
哪些人是「土豪」、哪些人家裡有小孩等。這就屬於無監督學習的分群
問題。
這兩種機器學習類別的最大區別是，監督式學習的訓練資料裡有已知的
結果來「監督」；而無監督學習的訓練資料裡沒有結果「監督」，不知道
到底能分析出什麼樣的結果。
```

```
機器學習應用程式開發的典型步驟
本節透過－個實例來介紹一下機器學習應用程式開發的典型步驟，以及
機器學習領域的—些常用概念。假設，我們要開發－個房價評估系統，
系統的目標是對一個已知特徵的房子價格進行評估預測。建立這樣—個
系統需要包含以下幾個步驟。

1.4.1 資料獲取和標記
我們需要大量不同特徵的房子和所對應的價格資訊，可以直接從房產評
估中心取得房子的相關資訊，如房子的面積、地理位置、朝向、價格
等。另外還有一些資訊房產評估中心不一定有，例如房子所在地的學校
情況，這—特徵常常會影響房子的價格，這個時候就需要透過其他途徑
收集這些資料，這些資料叫做訓鍊樣本，或資料集。房子的面積、地
理位置等稱為特徵。在資料獲取階段，需要收集儘量多的特徵。特徵越
全，資料越多，訓練出來的模型才會越準確。
透過這個過程也可以咸受到資料獲取的成本可能是很高的。人們常説石
油是黑色的「黃金」，在人工智慧時代，資料成了透明的「石油」，這
也説明為什麼螞蟻金服估值這麼高了。螞蟻金服有巨量的使用者交易資
料，據此他們可以計算出使用者的信用指標，稱為芝麻信用，根據芝麻
信用給你—定的預支額，這就是一家新的信用卡公司了。而這還只是單
單—個點的價值，真正的價值在於網際網路金融。
在房價評估系統這個實例裡，我們的房子價格資訊是從房產評估中心獲
得的，這—資料可能不準確。有時為了避税，房子的評估價格會比房子
的真實交易價格低很多。這時，就需要擷取房子的實際成交價格，這—

1.4 機器學習應用程式開發的典型步驟
過程稱為資料標記。標記可以是人工標記，例如—個－個從房產仲介那
打聽房子的實際成交價格；也可以是自動標記，例如透過分析資料，找
出房產評估中心給的房子評估價格和真實成交價格的比對關係，然後直
接算出來。資料標記對有監督的學習方法是必須的。舉例來説，針對垃
圾郵件過濾系統，我們的訓練範例必須包含這個郵件是否為垃圾郵件的
標記資料。

1.4.2 資料清洗
假設我們擷取到的資料裡，關於房子面積，有按平方公尺計算的，也有
按平方英尺計算的，這時需要對面積單位進行統—。這個過程稱為資料
清洗。資料清洗還包含去掉重複的資料及雜訊資料，讓資料具備結構化
特徵，以方便作為機器學習演算法的輸入。

1.4.3 特徵選擇
假設我們擷取到了100 個房子的特徵，透過—個—個分析這些特徵，最
後選擇了30 個特徵作為輸入。這個過程稱為特徵逯擇。特徵選擇的方法
之—是人工選擇方法，即對—個—個特徵進行人員分析，然後選擇合適
的特徵集合。另外一個方法是透過模型來自動完成，如本書即將介紹的
PCA 演算法。

1.4.4 模型選擇
房價評估系統是屬於監督式學習的回歸學習類型，我們可以選擇最簡單
的線性方程來模擬。選搓哪個模型，和問題領域、資料量大小、訓練時
長、模型的準確度等多方面有關。這方面的內容將在第3 章介紹。


1.4.5 模型訓練和測試
把資料集分成訓練資料集和測試資料集，一般按照8:2 或7:3 來劃分，然
後用訓練資料集來訓練模型。訓練出參數後再使用測試資料集來測試樸
型的準確度。為什麼要單獨分出一個測試資料集來做測試呢？答案是必
須確保測試的準確性，即模型的準確性是要用它「沒見過」的資料來測
試，而不能用那些用來訓練這個模型的資料來測試。理論上更合理的資
料集劃分方案是分成3 個，此外還要再加－個交換驗證資料集。


1.4.6 模型效能評估和最佳化
模型出來後，我們需要對機器學習的演算法模型進行效能評估。效能評
估包含很多方面，實際如下。
訓練時長是指需要花多長時間來訓練這個模型。對一些巨量資料的機器
學習應用，可能需要1 個月甚至更長的時間來訓練—個模型，這個時候
演算法的訓練效能就變得很重要了。
另外，還需要判斷資料集是否足夠多，—般而言，對於複雜特徵的系
統，訓練資料集越大越好。然後還需要判斷模型的準確性，即對－個新
的資料是否可準確地進行預測。最後需要判斷模型是否能滿足應用場景
的效能要求，如果不能滿足要求，就需要最佳化，然後繼續對模型進行
訓練和評估，或更換為其他模型。

1.4.7 模型使用
訓練出來的模型可以把參數儲存起來，下次使用時直接載入即可。—般
來講，模型訓練需要的計算量是很大的，也需要較長的時間來訓練，這
是因為—個好的模型參數，需要對大類型資料集進行訓練後才能獲得。
而真正使用模型時，其計算量是比較少的，—般是直接把新樣本作為輸
入，然後呼叫模型即可得出預測結果。
本書的重點放在機器學習的演算法介紹以及scikit-learn 工具套件的使用
上。對資料獲取、資料清洗、特徵選擇等內容沒有深入介紹，但並不代
表這些內容不重要。在實際工程應用領域，由於機器學習演算法模型只
有固定的幾種，而資料獲取、標記丶清洗、特徵選擇等常常和實際的應
用場景相關，機器學習工程應用領域的工程師進行處理更多的反而是這
些內容。
```
```
ChapterQ3 機器學習理論基礎
3.1 過擬合和欠擬合
3.2 成本函數
3.3 模型準確性
3.3.1 模型效能的不同表述方式
3.3.2 交換驗證資料集
3.4 學習曲線
3.4.1 實例：畫出學習曲線
3.4.2 過擬合和欠擬合的特徵
3.5 演算法模型效能最佳化
3.6 查準率和召回率
3.7 F1 Score
```
## 機器學習演算法
```
ChapterQ4 k－近鄰演算法
4.1 演算法原理
4.1.1 演算法優缺點
4.1.2 演算法參數
4.1.3 演算法的變種．
4.2 範例：使用k- 近鄰演算法進行分類
4.2 範例：使用k- 近鄰演算法進行回歸擬合
4.4.3 模型訓練及分析4-13
4.4.4 特徵選擇及資料
4.5 擴充閲讀
4.5.1 如何加強k- 近鄰演算法的運算效率
4.5.2 相關性測試

ChapterQS 線性回歸演算法
5.1 演算法原理
5.1.1 預測函數
5.1.2 成本函數
5.1.3 梯度下降演算法
5.2 多變數線性回歸演算法
5.2.1 預測函數
5.2.2 成本函數
5.2.3 梯度下降演算法
5.3 模型最佳


5.3.1 多項式與線性回歸
5.3.2 資料歸一
5.4 範例：使用線性回歸演算法擬合正弦函數

5.5 範例：測算房價
5.5.1 輸入特徵
5.5.2 模型訓練
5.5.3 模型最佳化
5.5.4 學習曲線
5.6.1 梯度下降反覆運算公式推導
5.6.2 隨機梯度下降演算法
5.6.3 標準方程式


決策樹
7.1.1 資訊增益
7.1.2 決策樹的建立

7.1.3 剪枝演算法
7.2 演算法參數
7.3 實例：預測鐵達尼號倖存者
7.3.1 資料分析
7.3.2 模型訓練
733 最佳化模型參數7-16
7.3.4 模型參數選擇工具套件
7.4.1 熵和條件熵

的建置演算法
7.5.1 自助聚合演算法Bagging

7.5.2 正向激勵演算法boosting
7.5.3 隨機森林
7.5.4 ExtraTrees 演算法


支援向量機
8.1 演算法原理
8.1.1 大間距分類演算法
8.1.2 鬆弛係數
8.2 核心函數
8.2.1 最簡單的核心函數
8.2.2 相似性函數
8.3 scikit-learn 裡的SVM


Chapter 11 k- 平均值演算法
11.1 演算法原埋
11. 1. 1 k- 平均值演算法成本函數
11.1.2 隨機初始化分群中心點
11.1.3 選擇分群的個數
11.2 sci kit-learn 裡的k- 平均值演算法
11.3 使用k- 平均值對文件進行分群分析

11.3.1 準備資料集
11.3.2 載入資料集
11.3.3 文字分群分析

11.4 分群演算法效能評估
11.4.1 Adjust Rand Index
1 1.4.2 齊次「生和完整性
輪廓係數.

```

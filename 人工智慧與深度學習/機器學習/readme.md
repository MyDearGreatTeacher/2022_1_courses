
#
```
ChapterQ1 機器學習介紹
1.1 什麼是機器學習
1.2 機器學習有什麼用

1.3 機器學習的分類
1.4 機器學習應用程式開發的典型步驟
1.4.1 資料獲取和標記
1.4.2 資料清洗
1.4.3 特徵選擇
1.4.4 模型選擇
1.4.5 模型訓練和測試
1.4.6 模型效能評估和最佳化
1.4.7 模型使用
```
```

```
```
ChapterQ3 機器學習理論基礎
3.1 過擬合和欠擬合
3.2 成本函數
3.3 模型準確性
3.3.1 模型效能的不同表述方式
3.3.2 交換驗證資料集
3.4 學習曲線
3.4.1 實例：畫出學習曲線
3.4.2 過擬合和欠擬合的特徵
3.5 演算法模型效能最佳化
3.6 查準率和召回率
3.7 F1 Score
```
## 機器學習演算法
```
ChapterQ4 k－近鄰演算法
4.1 演算法原理
4.1.1 演算法優缺點
4.1.2 演算法參數
4.1.3 演算法的變種．
4.2 範例：使用k- 近鄰演算法進行分類
4.2 範例：使用k- 近鄰演算法進行回歸擬合
4.4.3 模型訓練及分析4-13
4.4.4 特徵選擇及資料
4.5 擴充閲讀
4.5.1 如何加強k- 近鄰演算法的運算效率
4.5.2 相關性測試

ChapterQS 線性回歸演算法
5.1 演算法原理
5.1.1 預測函數
5.1.2 成本函數
5.1.3 梯度下降演算法
5.2 多變數線性回歸演算法
5.2.1 預測函數
5.2.2 成本函數
5.2.3 梯度下降演算法
5.3 模型最佳


5.3.1 多項式與線性回歸
5.3.2 資料歸一
5.4 範例：使用線性回歸演算法擬合正弦函數

5.5 範例：測算房價
5.5.1 輸入特徵
5.5.2 模型訓練
5.5.3 模型最佳化
5.5.4 學習曲線
5.6.1 梯度下降反覆運算公式推導
5.6.2 隨機梯度下降演算法
5.6.3 標準方程式


決策樹
7.1.1 資訊增益
7.1.2 決策樹的建立

7.1.3 剪枝演算法
7.2 演算法參數
7.3 實例：預測鐵達尼號倖存者
7.3.1 資料分析
7.3.2 模型訓練
733 最佳化模型參數7-16
7.3.4 模型參數選擇工具套件
7.4.1 熵和條件熵

的建置演算法
7.5.1 自助聚合演算法Bagging

7.5.2 正向激勵演算法boosting
7.5.3 隨機森林
7.5.4 ExtraTrees 演算法


支援向量機
8.1 演算法原理
8.1.1 大間距分類演算法
8.1.2 鬆弛係數
8.2 核心函數
8.2.1 最簡單的核心函數
8.2.2 相似性函數
8.3 scikit-learn 裡的SVM


Chapter 11 k- 平均值演算法
11.1 演算法原埋
11. 1. 1 k- 平均值演算法成本函數
11.1.2 隨機初始化分群中心點
11.1.3 選擇分群的個數
11.2 sci kit-learn 裡的k- 平均值演算法
11.3 使用k- 平均值對文件進行分群分析

11.3.1 準備資料集
11.3.2 載入資料集
11.3.3 文字分群分析

11.4 分群演算法效能評估
11.4.1 Adjust Rand Index
1 1.4.2 齊次「生和完整性
輪廓係數.

```
